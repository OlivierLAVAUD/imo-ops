# Web Scraping to Json files (c1-scrap)

Ce projet est un scraper automatis√© d√©velopp√© en Python pour extraire des donn√©es immobili√®res depuis le site IAD France. 

Utilisant Playwright pour le navigateur headless, il permet de collecter des informations d√©taill√©es sur les annonces immobili√®res incluant les caract√©ristiques du bien, les prix, les photos, les performances √©nerg√©tiques (DPE/GES), les informations de copropri√©t√© et les coordonn√©es des conseillers.

 Le scraper int√®gre une gestion intelligente des cookies avec plusieurs strat√©gies de contournement, une extraction avanc√©e des m√©dias (photos, vid√©os, visites virtuelles), et supporte la pagination pour collecter des donn√©es √† grande √©chelle.
 
 Configuration via fichier JSON, export des r√©sultats structur√©s et param√©trage flexible font de cet outil une architecture de solution compl√®te pour l'analyse du march√© immobilier fran√ßais √† partir du web.

## üõ† Stack Technologique
### Langage & Environnement

    - Python 3.7+ - Langage principal avec support asynchrone
    - Asyncio - Pour le traitement concurrent et les op√©rations I/O non-bloquantes

### Web Scraping & Automatisation
    - Playwright - Navigation headless moderne avec support multi-navigateurs
    - Async API - Version asynchrone pour des performances optimales

### Traitement des Donn√©es

    - JSON - Configuration et export des donn√©es
    - Regex - Extraction et nettoyage des textes
    - Typing - Annotations de types pour la maintenabilit√©

### Architecture & Conception

    - Programmation Orient√©e Objet - Design modulaire et extensible

    - Classes Sp√©cialis√©es :

        - CookieManager - Gestion intelligente des consentements
        - DataExtractor - Extraction structur√©e des donn√©es
        - MediaExtractor - Traitement des m√©dias et photos
        - PerformanceEnergetiqueExtractor - Analyse DPE/GES

### S√©lecteurs & Parsing

    - CSS Selectors - Localisation des √©l√©ments principaux
    - XPath - S√©lecteurs avanc√©s pour cas complexes
    - Text Processing - Nettoyage et validation des donn√©es

### Gestion de Configuration

    - Fichiers JSON - Configuration flexible du scraping
    - Variables d'environnement - Param√©trage d√©ploiement
    - Arguments CLI - Interface en ligne de commande

### Fonctionnalit√©s Avanc√©es

    - Gestion d'erreurs robuste - Continuit√© de service
    - Pagination automatique - Collecte multi-pages
    - D√©lais configurables - Respect des politiques sites
    - Export structur√© - Donn√©es pr√™tes pour analyse

# Prerequisite

    - uv: 
    - config.json: fichier r√©f√©rencant les proprietes d'acessibilit√© du site web, d√©sirant √™tre collect√©es, ainsi que 

# Installation

## with sources
```bash

git clone https://OlivierLAVAUD/imo-ops.git 
cd immo-ops
uv sync

cd c1-scrap

uv run iad_scraper.py
```

## with dockerfile


```bash
# Construire l'image
docker build -t iad-scraper .

# Ex√©cuter avec param√®tres par d√©faut
docker run -it --rm iad-scraper

# Ex√©cuter avec param√®tres personnalis√©s (Powershell)
docker run -it --rm `
  -v "${PWD}/results:/app/results" `
  -e LOCALISATION="Lyon" `
  -e MAX_BIENS=10 `
  iad-scraper

# Linux Ubuntu
docker run -it --rm \
  -v "$(pwd)/results:/app/results" \
  -e LOCALISATION="Lyon" \
  -e MAX_BIENS=10 \
  iad-scraper

```

## with docker-compose
```bash
# Avec les valeurs par d√©faut
docker-compose up iad-scraper

# Avec des variables personnalis√©es ( powershell)
$env:MAX_BIENS=10; $env:LOCALISATION="Marseille"; docker-compose up iad-scraper-custom

# vec des variables personnalis√©es Linux/Ubunu
MAX_BIENS=10 LOCALISATION="Marseille" docker-compose up iad-scraper-custom

```
